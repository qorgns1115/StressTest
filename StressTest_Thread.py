import subprocess
import json
import time
import pandas as pd
import schedule
import os
from datetime import datetime
import requests
from typing import Dict, Tuple, Optional

# API ì—”ë“œí¬ì¸íŠ¸ ë° HTTP ë©”ì„œë“œ ì„¤ì •
API_ENDPOINTS = {
    "/v1/user/verify": "POST",
    "/v1/system/health": "GET",
    "/v1/comms/member": "POST",
    "/v1/comms/mobile-join": "POST",
    "/v1/comms/mobile-usage": "POST",
    "/v1/comms/mobile-bills": "POST",
    "/v1/comms/mobile-payments": "POST"
}
# asdasdfasdfdsaf
# ì—”ë“œí¬ì¸íŠ¸ë³„ Header ì„¤ì •
ENDPOINT_HEADERS = {
    "/v1/user/verify": {
        "X-Api-Tx-Id": "12345",
        "X-Src-Inst-Cd": "SRC001",
        "X-Dst-Inst-Cd": "DST001",
        "Content-Type": "application/json"
    },
    "/v1/system/health": {
        "X-Api-Tx-Id": "12345"
    },
    "default": {
        "X-Api-Tx-Id": "12345",
        "X-Src-Inst-Cd": "SRC001",
        "X-Dst-Inst-Cd": "DST001",
        "X-Api-Type": "application/json",
        "Content-Type": "application/json"
    }
}

# Request Bodies ì„¤ì •
REQUEST_BODIES = {
    "/v1/user/verify": '{"user_id": "test_user"}',
    "/v1/comms/member": '{"user_id": "test_user", "search_timestamp": "2025-02-10", "next_page": "2000","limit": 1}',
    "/v1/comms/mobile-join": '{"user_id": "test_id", "search_timestamp": "2025-02-10", "ctrt_mng_no": "100001"}',
    "/v1/comms/mobile-usage": '{"user_id": "test_user", "search_timestamp": "2025-02-10", "ctrt_mng_no": "20", "bgng_ym": "2024-12", "end_ym": "2025-01"}',
    "/v1/comms/mobile-bills": '{"user_id": "test_user", "search_timestamp": "2025-02-10", "ctrt_mng_no": "20", "bgng_ym": "2024-12", "end_ym": "2025-01"}',
    "/v1/comms/mobile-payments": '{"user_id": "test_user", "search_timestamp": "2025-02-10", "ctrt_mng_no": "20", "bgng_ym": "2024-12", "end_ym": "2025-01"}'
}

# JMeter ì‹¤í–‰ ê²½ë¡œ
JMETER_PATH = r"C:\Users\Administrator\Downloads\apache-jmeter-5.6.3\apache-jmeter-5.6.3\bin\jmeter.bat"

def run_jmeter_test(jmx_file, results_dir):
    """
    JMeter í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    :param jmx_file: JMeter í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ
    :param results_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
    :return: (ì„±ê³µ ì—¬ë¶€, ê²°ê³¼ íŒŒì¼ ê²½ë¡œ)
    """
    result_file = os.path.join(results_dir, "test_results.jtl") #ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ë‘ jtl íŒŒì¼ ì—°ê²°
    log_file = os.path.join(results_dir, "jmeter.log")
    
    print(f"ğŸš€ JMeter í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {results_dir}")
    
    cmd = f'"{JMETER_PATH}" -n -t "{jmx_file}" -l "{result_file}" -j "{log_file}"' #jmeter ì‹¤í–‰ íŒŒì¼ ê²½ë¡œ, gui ì—†ì´, test plan, log file ê²½ë¡œ, jmeter log file ê²½ë¡œ ì§€ì •
    
    try:
        # JMeter ì‹¤í–‰ ë° ì‹¤ì‹œê°„ ì¶œë ¥ ìº¡ì²˜
        process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True) #ì‹¤í–‰ëœ í”„ë¡œì„¸ìŠ¤ê°€ ëë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì§€ ì•ŠëŠ” ë¹„ë™ê¸° ì‹¤í–‰ ë°©ì‹
        #í‘œì¤€ì¶œë ¥ì„ íŒŒì´í”„ë¡œ ì—°ê²° > í”„ë¡œì„¸ìŠ¤ì˜ ì¶œë ¥ì„ íŒŒì´ì¬ ì½”ë“œì—ì„œ ì½ì„ ìˆ˜ ìˆìŒ, í‘œì¤€ì—ëŸ¬ë¥¼ í‘œì¤€ì¶œë ¥ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸í•¨ìœ¼ë¡œì¨ ì¼ë°˜ ì¶œë ¥ê³¼ ì—ëŸ¬ ë©”ì‹œì§€ê°€ ëª¨ë‘ ê°™ì€ íŒŒì´í”„ë¡œ ì „ë‹¬ë¼ì„œ ì—ëŸ¬ì™€ ì¼ë°˜ ì¶œë ¥ì„ í•¨ê»˜ ì²˜ë¦¬
        #ì…ì¶œë ¥ì„ ë¬¸ìì—´ë¡œ ì²˜ë¦¬í•˜ë„ë¡ ì§€ì •
        
        while True:
            output = process.stdout.readline()
            if output == '' and process.poll() is not None: #outputì´ ê³µë°±ì´ê±°ë‚˜, pollì´ not none(ì‹¤í–‰ëœ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ)ë™ì‹œì— ë˜ë©´ ë£¨í”„ ë¹ ì ¸ë‚˜ê°
                break
            if output:
                print(output.strip())
        
        return_code = process.poll()
        
        if return_code == 0:
            print("âœ… JMeter í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            return True, result_file
        else:
            print(f"âŒ JMeter ì‹¤í–‰ ì‹¤íŒ¨ (ë°˜í™˜ ì½”ë“œ: {return_code})")
            return False, None
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False, None

def get_user_input():
    """ê¸°ë³¸ ì„œë²„ ì„¤ì • ì •ë³´ ì…ë ¥ ë°›ê¸°"""
    print("ğŸ“Œ JMeter ìë™í™” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê¸°ë³¸ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    protocol = input("Protocol (http/https): ").strip()
    server_name = input("Server Name or IP: ").strip()
    port = input("Port Number (ì˜ˆ: 8080): ").strip()
    
    return {
        "protocol": protocol,
        "server_name": server_name,
        "port": port
    }

class StressTestController:
    def __init__(self, initial_threads=610, thread_increment=5, max_threads=1000,
                 error_threshold=5, response_time_threshold=5000):
        """
        ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì»¨íŠ¸ë¡¤ëŸ¬ ì´ˆê¸°í™”
        :param initial_threads: ì´ˆê¸° ì“°ë ˆë“œ ìˆ˜ (ê¸°ë³¸ê°’: 10)
        :param thread_increment: ë‹¨ê³„ë³„ ì“°ë ˆë“œ ì¦ê°€ëŸ‰ (ê¸°ë³¸ê°’: 10)
        :param max_threads: ìµœëŒ€ ì“°ë ˆë“œ ìˆ˜ (ê¸°ë³¸ê°’: 1000)
        :param error_threshold: ì˜¤ë¥˜ìœ¨ ì„ê³„ê°’(%) (ê¸°ë³¸ê°’: 5%)
        :param response_time_threshold: ì‘ë‹µì‹œê°„ ì„ê³„ê°’(ms) (ê¸°ë³¸ê°’: 5000ms)
        """
        self.initial_threads = initial_threads
        self.thread_increment = thread_increment
        self.max_threads = max_threads
        self.error_threshold = error_threshold  # í—ˆìš© ê°€ëŠ¥í•œ ìµœëŒ€ ì˜¤ë¥˜ìœ¨
        self.response_time_threshold = response_time_threshold  # í—ˆìš© ê°€ëŠ¥í•œ ìµœëŒ€ ì‘ë‹µ ì‹œê°„
        self.current_threads = initial_threads
        self.test_phase = "running"
        self.failure_detected = False
        self.failure_reason = None
        
    def should_continue(self, stats: Dict) -> Tuple[bool, Optional[str]]:
        """
        í…ŒìŠ¤íŠ¸ ì§€ì† ì—¬ë¶€ ê²°ì •
        :param stats: í˜„ì¬ í…ŒìŠ¤íŠ¸ í†µê³„
        :return: (ê³„ì† ì§„í–‰ ì—¬ë¶€, ì¤‘ë‹¨ ì‚¬ìœ )
        """
        if stats["error_rate"] > self.error_threshold:
            return False, f"ì˜¤ë¥˜ìœ¨ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í•¨: {stats['error_rate']}%"
        
        if stats["avg_response_time"] > self.response_time_threshold:
            return False, f"ì‘ë‹µ ì‹œê°„ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í•¨: {stats['avg_response_time']}ms"
            
        if self.current_threads >= self.max_threads:
            return False, f"ìµœëŒ€ ì“°ë ˆë“œ ìˆ˜ì— ë„ë‹¬í•¨: {self.max_threads}"
            
        return True, None

    def increment_threads(self) -> int:
        """ë‹¤ìŒ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ë¥¼ ìœ„í•œ ì“°ë ˆë“œ ìˆ˜ ì¦ê°€"""
        self.current_threads += self.thread_increment
        return self.current_threads

def create_jmx_file(config, results_dir, thread_count, filename="generated_test.jmx"):
    """
    JMeter í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ìƒì„±
    :param config: ì„œë²„ ì„¤ì • ì •ë³´
    :param results_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
    :param thread_count: í˜„ì¬ ì“°ë ˆë“œ ìˆ˜
    :param filename: ìƒì„±í•  íŒŒì¼ëª…
    """
    full_path = os.path.join(results_dir, filename)
    
    jmx_template = f'''<?xml version="1.0" encoding="UTF-8"?>
<jmeterTestPlan version="1.2" properties="5.0" jmeter="5.6.3">
  <hashTree>
    <TestPlan guiclass="TestPlanGui" testclass="TestPlan" testname="Stress Test Plan" enabled="true">
      <stringProp name="TestPlan.comments"></stringProp>
      <boolProp name="TestPlan.functional_mode">false</boolProp>
      <boolProp name="TestPlan.tearDown_on_shutdown">true</boolProp>
      <boolProp name="TestPlan.serialize_threadgroups">false</boolProp>
      <elementProp name="TestPlan.user_defined_variables" elementType="Arguments" guiclass="ArgumentsPanel" testclass="Arguments" testname="User Defined Variables" enabled="true">
        <collectionProp name="Arguments.arguments"/>
      </elementProp>
      <stringProp name="TestPlan.user_define_classpath"></stringProp>
    </TestPlan>
    <hashTree>'''

    # ê° API ì—”ë“œí¬ì¸íŠ¸ì— ëŒ€í•œ ì“°ë ˆë“œ ê·¸ë£¹ ì„¤ì •
    for endpoint, method in API_ENDPOINTS.items():
        headers = ENDPOINT_HEADERS.get(endpoint, ENDPOINT_HEADERS['default'])
        body = REQUEST_BODIES.get(endpoint, "")
        
        jmx_template += f''' #ê° ì—”ë“œí¬ì¸íŠ¸ì— ëŒ€í•œ ì“°ë ˆë“œ ê·¸ë£¹ ì–´ë–»ê²Œ ì„¤ì •í•  ì§€?
      <ThreadGroup guiclass="ThreadGroupGui" testclass="ThreadGroup" testname="{endpoint} Test" enabled="true">
        <stringProp name="ThreadGroup.on_sample_error">continue</stringProp>
        <elementProp name="ThreadGroup.main_controller" elementType="LoopController" guiclass="LoopControlPanel" testclass="LoopController" testname="Loop Controller" enabled="true">
          <boolProp name="LoopController.continue_forever">false</boolProp>
          <stringProp name="LoopController.loops">1</stringProp>
        </elementProp>
        <stringProp name="ThreadGroup.num_threads">{thread_count}</stringProp>
        <stringProp name="ThreadGroup.ramp_time">1</stringProp>
        <boolProp name="ThreadGroup.scheduler">true</boolProp>
        <stringProp name="ThreadGroup.duration">30</stringProp>
        <stringProp name="ThreadGroup.delay"></stringProp>
        <boolProp name="ThreadGroup.same_user_on_next_iteration">true</boolProp>
      </ThreadGroup>
      <hashTree>
        <HTTPSamplerProxy guiclass="HttpTestSampleGui" testclass="HTTPSamplerProxy" testname="{endpoint}" enabled="true">
          <boolProp name="HTTPSampler.postBodyRaw">true</boolProp>
          <elementProp name="HTTPsampler.Arguments" elementType="Arguments">
            <collectionProp name="Arguments.arguments">'''

        if method == "POST" and body:
            jmx_template += f'''
              <elementProp name="" elementType="HTTPArgument">
                <boolProp name="HTTPArgument.always_encode">false</boolProp>
                <stringProp name="Argument.value">{body}</stringProp>
                <stringProp name="Argument.metadata">=</stringProp>
              </elementProp>'''

        jmx_template += f'''
            </collectionProp>
          </elementProp>
          <stringProp name="HTTPSampler.domain">{config['server_name']}</stringProp>
          <stringProp name="HTTPSampler.port">{config['port']}</stringProp>
          <stringProp name="HTTPSampler.protocol">{config['protocol']}</stringProp>
          <stringProp name="HTTPSampler.contentEncoding">UTF-8</stringProp>
          <stringProp name="HTTPSampler.path">{endpoint}</stringProp>
          <stringProp name="HTTPSampler.method">{method}</stringProp>
          <boolProp name="HTTPSampler.follow_redirects">true</boolProp>
          <boolProp name="HTTPSampler.auto_redirects">false</boolProp>
          <boolProp name="HTTPSampler.use_keepalive">true</boolProp>
          <boolProp name="HTTPSampler.DO_MULTIPART_POST">false</boolProp>
          <stringProp name="HTTPSampler.embedded_url_re"></stringProp>
          <stringProp name="HTTPSampler.connect_timeout"></stringProp>
          <stringProp name="HTTPSampler.response_timeout"></stringProp>
        </HTTPSamplerProxy>
        <hashTree>
          <HeaderManager guiclass="HeaderPanel" testclass="HeaderManager" testname="HTTP Header Manager" enabled="true">
            <collectionProp name="HeaderManager.headers">'''

        for header_name, header_value in headers.items():
            jmx_template += f'''
              <elementProp name="" elementType="Header">
                <stringProp name="Header.name">{header_name}</stringProp>
                <stringProp name="Header.value">{header_value}</stringProp>
              </elementProp>'''

        jmx_template += '''
            </collectionProp>
          </HeaderManager>
          <hashTree/>
        </hashTree>
      </hashTree>'''

    # ê²°ê³¼ ìˆ˜ì§‘ê¸° ì¶”ê°€
    jmx_template += '''
      <ResultCollector guiclass="ViewResultsFullVisualizer" testclass="ResultCollector" testname="View Results Tree" enabled="true">
        <boolProp name="ResultCollector.error_logging">false</boolProp>
        <objProp>
          <name>saveConfig</name>
          <value class="SampleSaveConfiguration">
            <time>true</time>
            <latency>true</latency>
            <timestamp>true</timestamp>
            <success>true</success>
            <label>true</label>
            <code>true</code>
            <message>true</message>
            <threadName>true</threadName>
            <dataType>true</dataType>
            <encoding>false</encoding>
            <assertions>true</assertions>
            <subresults>true</subresults>
            <responseData>false</responseData>
            <samplerData>false</samplerData>
            <xml>false</xml>
            <fieldNames>true</fieldNames>
            <responseHeaders>false</responseHeaders>
            <requestHeaders>false</requestHeaders>
            <responseDataOnError>false</responseDataOnError>
            <saveAssertionResultsFailureMessage>true</saveAssertionResultsFailureMessage>
            <assertionsResultsToSave>0</assertionsResultsToSave>
            <bytes>true</bytes>
            <sentBytes>true</sentBytes>
            <url>true</url>
            <threadCounts>true</threadCounts>
            <idleTime>true</idleTime>
            <connectTime>true</connectTime>
          </value>
        </objProp>
        <stringProp name="filename"></stringProp>
      </ResultCollector>
      <hashTree/>
    </hashTree>
  </hashTree>
</jmeterTestPlan>'''

    with open(full_path, 'w', encoding='utf-8') as f:
        f.write(jmx_template)
    
    with open(full_path, 'w', encoding='utf-8') as f:
        f.write(jmx_template)
    return full_path

def analyze_results(jtl_file: str, results_dir: str) -> Dict:
    """
    í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„
    :param jtl_file: JMeter ê²°ê³¼ íŒŒì¼
    :param results_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
    :return: ë¶„ì„ëœ í†µê³„ ì •ë³´
    """
    df = pd.read_csv(jtl_file)
    
    # ë°ì´í„° íƒ€ì… ë³€í™˜ì„ ìœ„í•œ í•¨ìˆ˜
    def convert_to_serializable(value):
        if pd.api.types.is_integer_dtype(type(value)):
            return int(value)
        elif pd.api.types.is_float_dtype(type(value)):
            return float(value)
        return value
    
    stats = {
        "total_requests": int(len(df)),
        "error_rate": float((df['success'] == False).mean() * 100),
        "avg_response_time": float(df['elapsed'].mean()),
        "max_response_time": float(df['elapsed'].max()),
        "min_response_time": float(df['elapsed'].min()),
        "90th_percentile": float(df['elapsed'].quantile(0.90)),
        "95th_percentile": float(df['elapsed'].quantile(0.95)),
        "requests_per_second": float(len(df) / (df['timeStamp'].max() - df['timeStamp'].min()) * 1000),
        "error_count": int((df['success'] == False).sum())
    }
    
    # ëª¨ë“  ê°’ì„ ê¸°ë³¸ Python íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    serializable_stats = {k: convert_to_serializable(v) for k, v in stats.items()}

    # ìƒì„¸ í†µê³„ ì €ì¥
    with open(os.path.join(results_dir, f"phase_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"), 'w') as f:
        json.dump(serializable_stats, f, indent=4)
        
    return stats

def run_stress_test(config: Dict):
    """
    ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë©”ì¸ í•¨ìˆ˜
    :param config: ì„œë²„ ì„¤ì • ì •ë³´
    """
    base_results_dir = f"stress_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    os.makedirs(base_results_dir, exist_ok=True)
    
    # ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì»¨íŠ¸ë¡¤ëŸ¬ ì´ˆê¸°í™”
    controller = StressTestController()
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì • ê¸°ë¡
    with open(os.path.join(base_results_dir, "test_config.json"), 'w') as f:
        json.dump({
            "initial_threads": controller.initial_threads,
            "thread_increment": controller.thread_increment,
            "max_threads": controller.max_threads,
            "error_threshold": controller.error_threshold,
            "response_time_threshold": controller.response_time_threshold,
            "server_config": config
        }, f, indent=4)
    
    while True:
        phase_dir = os.path.join(base_results_dir, f"phase_{controller.current_threads}_threads")
        os.makedirs(phase_dir, exist_ok=True)
        
        print(f"\nğŸ”„ {controller.current_threads}ê°œì˜ ì“°ë ˆë“œë¡œ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ ì‹œì‘")
        
        # JMeter í…ŒìŠ¤íŠ¸ ìƒì„± ë° ì‹¤í–‰
        jmx_file = create_jmx_file(config, phase_dir, controller.current_threads)
        success, result_file = run_jmeter_test(jmx_file, phase_dir)
        
        if not success:
            print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨")
            controller.failure_detected = True
            controller.failure_reason = "JMeter ì‹¤í–‰ ì‹¤íŒ¨"
            break
            
        # ê²°ê³¼ ë¶„ì„
        stats = analyze_results(result_file, phase_dir)
        
        # ë‹¨ê³„ë³„ ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ë‹¨ê³„ë³„ ê²°ê³¼ (ì“°ë ˆë“œ ìˆ˜: {controller.current_threads})")
        print(f"ì´ˆë‹¹ ìš”ì²­ ìˆ˜: {stats['requests_per_second']:.2f}")
        print(f"í‰ê·  ì‘ë‹µ ì‹œê°„: {stats['avg_response_time']:.2f}ms")
        print(f"ì˜¤ë¥˜ìœ¨: {stats['error_rate']:.2f}%")
        print(f"90í¼ì„¼íƒ€ì¼ ì‘ë‹µ ì‹œê°„: {stats['90th_percentile']:.2f}ms")
        
        # ê³„ì† ì§„í–‰ ì—¬ë¶€ í™•ì¸
        should_continue, reason = controller.should_continue(stats)
        if not should_continue:
            print(f"\nğŸ›‘ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨: {reason}")
            controller.failure_detected = True
            controller.failure_reason = reason
            break
            
        # ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìœ„í•œ ì“°ë ˆë“œ ìˆ˜ ì¦ê°€
        controller.increment_threads()
        
        # ë‹¨ê³„ ê°„ ì¼ì‹œ ì¤‘ì§€
        time.sleep(5)
    

if __name__ == "__main__":
    print("ğŸš€ JMeter ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    config = get_user_input()
    run_stress_test(config)

#ì‚¬ìš©ì ì…ë ¥(í”„ë¡œí† ì½œ, ì„œë²„ ì£¼ì†Œ, í¬íŠ¸ ë²ˆí˜¸) > jmeter í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼(jmx) ìƒì„±(api ì—”ë“œí¬ì¸íŠ¸ì™€ ìš”ì²­ ë°©ì‹ ì„¤ì •, ì“°ë ˆë“œ ìˆ˜ì™€ ìš”ì²­ body, header ì„¤ì •, ìš”ì²­ì„ ë°˜ë³µí•  ì§€ ì—¬ë¶€ ì„¤ì •) > jmeter í…ŒìŠ¤íŠ¸ ì‹¤í–‰í•´ì„œ ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥(jmeterê°€ api ë¶€í•˜ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰ í›„ ì‘ë‹µ ë°ì´í„° ê¸°ë¡) > í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ jtl íŒŒì¼ì— ì €ì¥
# > í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„(í‰ê·  ì‘ë‹µ ì‹œê°„, ìµœëŒ€ ì‘ë‹µ ì‹œê°„, ì˜¤ë¥˜ìœ¨, ì´ˆë‹¹ ìš”ì²­ ìˆ˜)í›„ json íŒŒì¼ë¡œ ì €ì¥, ì´ë¡œ ì¸í•´ api ì„±ëŠ¥ ë°ì´í„° í™•ë³´ > stresstestcontrollerë¡œ thread ìˆ˜ ì¦ê°€ì‹œí‚¤ë©´ì„œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í•¨ > stress test ì‹¤í–‰ ë° ë°˜ë³µ, ì´ë¥¼ í†µí•´ apiì˜ ìµœëŒ€ ì²˜ë¦¬ ì„±ëŠ¥ê³¼ í•œê³„ì  íŒŒì•… > ë³´ê³ ì„œ ìƒì„±


#get user inputìœ¼ë¡œ ì‚¬ìš©ì ì…ë ¥ ë°›ê³ , jmeter í…ŒìŠ¤íŠ¸ íŒŒì¼ jmx íŒŒì¼ api ì—”ë“œí¬ì¸íŠ¸ë‘, http ìš”ì²­ë°©ì‹, í—¤ë”, ë°”ë”” ì´ëŸ°ê±° ì„¤ì •í•´ì„œ ë§Œë“¤ê³  jmetertest ì‹¤í–‰í•´ì„œ jtl íŒŒì¼ ë§Œë“¤ì–´ì„œ ë¡œê·¸ ì €ì¥í•˜ê³  stresstestcontroller ê°ì²´ ìƒì„±í•´ì„œ runstresstestí•´ì„œ ì ì§„ì ìœ¼ë¡œ ì“°ë ˆë“œìˆ˜ ëŠ˜ë ¤ê°€ë©´ì„œ ì„±ëŠ¥í…ŒìŠ¤íŠ¸ ë°˜ë³µí•˜ê³  jtl íŒŒì¼ ì½ì–´ì„œ api ì‘ë‹µì‹œê°„, ì˜¤ë¥˜ìœ¨, ìš”ì²­ ìˆ˜ ë“±ì˜ í†µê³„ ë¶„ì„, 
# ì´í›„ should_continue() í•¨ìˆ˜ë¡œ ì„ê³„ê°’ ì´ˆê³¼ ì—¬ë¶€ íŒë‹¨í•´ì„œ íŠ¹ì • ì¡°ê±´ ë°œìƒ ì‹œ ì¤‘ë‹¨
# ìµœëŒ€ ì“°ë ˆë“œ 620
 